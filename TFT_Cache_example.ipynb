{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFT Cache example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLNECaGMITEHuNLI4nmerX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoyahav/tft_notebooks/blob/main/TFT_Cache_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpktp9I6j2sA"
      },
      "source": [
        "!pip install tensorflow-transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALpc8RKFj7v9"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "import apache_beam as beam\n",
        "\n",
        "import tempfile\n",
        "import pprint\n",
        "import os"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP5obvUHj-TX",
        "outputId": "a2e2b846-cd2e-4eb2-bdc3-52f226f66395"
      },
      "source": [
        "span_0_key = tft_beam.analyzer_cache.DatasetKey('span-0')\n",
        "span_1_key = tft_beam.analyzer_cache.DatasetKey('span-1')\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "\n",
        "  return {\n",
        "      'x_mean':\n",
        "          tft.mean(inputs['x'], name='x') + tf.zeros_like(inputs['x']),\n",
        "  }\n",
        "feature_spec = {\n",
        "    'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "}\n",
        "\n",
        "input_metadata = dataset_metadata.DatasetMetadata(\n",
        "    schema_utils.schema_from_feature_spec(feature_spec))\n",
        "\n",
        "input_cache = {}\n",
        "\n",
        "\n",
        "cache_dir = tempfile.mkdtemp()\n",
        "\n",
        "#### Iteration 0 - only span-0 as analysis data, no cache #####\n",
        "\n",
        "input_data_dict = {\n",
        "    span_0_key: [{'x': x} for x in range(0, 100)],\n",
        "}\n",
        "\n",
        "filtered_analysis_dataset_keys = (\n",
        "    tft_beam.analysis_graph_builder.get_analysis_dataset_keys(\n",
        "        preprocessing_fn, feature_spec,\n",
        "        list(input_data_dict.keys()), input_cache, True))\n",
        "print('Analysis dataset keys required: {}'.format(filtered_analysis_dataset_keys))\n",
        "assert len(filtered_analysis_dataset_keys) == 1\n",
        "\n",
        "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "  with beam.Pipeline() as p:\n",
        "    transform_fn, output_cache = (\n",
        "        (input_data_dict, input_cache, input_metadata) | tft_beam.AnalyzeDatasetWithCache(\n",
        "            preprocessing_fn))\n",
        "    \n",
        "    output_cache | tft_beam.analyzer_cache.WriteAnalysisCacheToFS(p, cache_dir)\n",
        "    \n",
        "    transform_data = p | 'CreateTransformDataIteration0' >> beam.Create(input_data_dict[span_0_key])\n",
        "    transformed_dataset = ((transform_data, input_metadata), transform_fn) | tft_beam.TransformDataset()\n",
        "    transformed_data, transformed_metadata = transformed_dataset\n",
        "    transformed_data | beam.combiners.Sample.FixedSizeGlobally(1) | beam.Map(pprint.pprint)\n",
        "\n",
        "\n",
        "\n",
        "#### Iteration 1 - span-0 and span-1 as analysis data, span-0 has cache #####\n",
        "\n",
        "input_data_dict.update({\n",
        "    span_1_key: [{'x': x} for x in range(100, 200)],\n",
        "})\n",
        "\n",
        "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "  with beam.Pipeline() as p:\n",
        "    input_cache = p | 'ReadCache' >> tft_beam.analyzer_cache.ReadAnalysisCacheFromFS(cache_dir, [span_0_key, span_1_key])\n",
        "\n",
        "    filtered_analysis_dataset_keys = (\n",
        "        tft_beam.analysis_graph_builder.get_analysis_dataset_keys(\n",
        "            preprocessing_fn, feature_spec,\n",
        "            [span_0_key, span_1_key], input_cache, True))\n",
        "    print('Analysis dataset keys required: {}'.format(filtered_analysis_dataset_keys))\n",
        "    assert len(filtered_analysis_dataset_keys) == 1\n",
        "\n",
        "    transform_fn, output_cache = (\n",
        "        (input_data_dict, input_cache, input_metadata) | tft_beam.AnalyzeDatasetWithCache(\n",
        "            preprocessing_fn))\n",
        "    \n",
        "    output_cache | tft_beam.analyzer_cache.WriteAnalysisCacheToFS(p, cache_dir)\n",
        "    \n",
        "    transform_data = p | 'CreateTransformDataIteration1' >> beam.Create(input_data_dict[span_0_key])\n",
        "    transformed_dataset = ((transform_data, input_metadata), transform_fn) | tft_beam.TransformDataset()\n",
        "    transformed_data, transformed_metadata = transformed_dataset\n",
        "    transformed_data | beam.combiners.Sample.FixedSizeGlobally(1) | beam.Map(pprint.pprint)\n",
        "\n",
        "\n",
        "\n",
        "#### Iteration 2 - No new data, no analysis needed #####\n",
        "\n",
        "# No need to even read the dataset.\n",
        "input_data_dict = {\n",
        "    span_0_key: [],\n",
        "    span_1_key: [],\n",
        "}\n",
        "\n",
        "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
        "  with beam.Pipeline() as p:\n",
        "    input_cache = p | 'ReadCache' >> tft_beam.analyzer_cache.ReadAnalysisCacheFromFS(cache_dir, [span_0_key, span_1_key])\n",
        "    \n",
        "    filtered_analysis_dataset_keys = (\n",
        "        tft_beam.analysis_graph_builder.get_analysis_dataset_keys(\n",
        "            preprocessing_fn, feature_spec,\n",
        "            [span_0_key, span_1_key], input_cache, True))\n",
        "    print('Analysis dataset keys required: {}'.format(filtered_analysis_dataset_keys))\n",
        "    assert len(filtered_analysis_dataset_keys) == 0\n",
        "\n",
        "    transform_fn, output_cache = (\n",
        "        (input_data_dict, input_cache, input_metadata) | tft_beam.AnalyzeDatasetWithCache(\n",
        "            preprocessing_fn))\n",
        "    \n",
        "    output_cache | tft_beam.analyzer_cache.WriteAnalysisCacheToFS(p, cache_dir)\n",
        "    \n",
        "    transform_data = p | 'CreateTransformDataIteration2' >> beam.Create([{'x': 1}])\n",
        "    transformed_dataset = ((transform_data, input_metadata), transform_fn) | tft_beam.TransformDataset()\n",
        "    transformed_data, transformed_metadata = transformed_dataset\n",
        "    transformed_data | beam.combiners.Sample.FixedSizeGlobally(1) | beam.Map(pprint.pprint)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tmppik594kh\n",
            "Analysis dataset keys required: {DatasetKey(key='span-0')}\n",
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-9e98fd81-403e-4b56-95c5-a1845f34589a.json']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmr0w3pat/tftransform_tmp/557ca93612ef4b12a0112b85ab98fba6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmr0w3pat/tftransform_tmp/557ca93612ef4b12a0112b85ab98fba6/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmr0w3pat/tftransform_tmp/1052ad75faa24a15b83fac079a71dad0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmr0w3pat/tftransform_tmp/1052ad75faa24a15b83fac079a71dad0/assets\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-9e98fd81-403e-4b56-95c5-a1845f34589a.json']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'x_mean': 49.5}]\n",
            "Analysis dataset keys required: {DatasetKey(key='span-1')}\n",
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnzio4s48/tftransform_tmp/221973b6727a4baeb42dc2bf58cf19ee/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnzio4s48/tftransform_tmp/221973b6727a4baeb42dc2bf58cf19ee/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnzio4s48/tftransform_tmp/6bd8f47e958944e18561a09cded3bd6b/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnzio4s48/tftransform_tmp/6bd8f47e958944e18561a09cded3bd6b/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'x_mean': 99.5}]\n",
            "Analysis dataset keys required: set()\n",
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.4.1) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjswz9sxq/tftransform_tmp/30ac848bd1c243a9bfeca632d377e729/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjswz9sxq/tftransform_tmp/30ac848bd1c243a9bfeca632d377e729/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'x_mean': 99.5}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}