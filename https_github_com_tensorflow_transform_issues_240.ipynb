{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "https://github.com/tensorflow/transform/issues/240.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoyahav/tft_notebooks/blob/main/https_github_com_tensorflow_transform_issues_240.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4hMnK6gWme"
      },
      "source": [
        "!pip install tensorflow-transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOHulalcghYm",
        "outputId": "0940fd5d-c720-4377-c739-75e8c93e808f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "print(tft.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDh6CCe8gZEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657ba888-6390-4892-c940-4732df2ba293"
      },
      "source": [
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata, schema_utils\n",
        "\n",
        "import contextlib2\n",
        "\n",
        "_TEMP_DIR = tempfile.mkdtemp()\n",
        "_LABEL_KEY = \"label\"\n",
        "_INT_DTYPE = tf.int64\n",
        "_FLOAT_DTYPE = tf.float32\n",
        "\n",
        "\n",
        "def _generate_data_vector():\n",
        "    train_raw_data = [\n",
        "        {_LABEL_KEY: [1]},\n",
        "        {_LABEL_KEY: [0]},\n",
        "        {_LABEL_KEY: [0]},\n",
        "        {_LABEL_KEY: [0]},\n",
        "    ]\n",
        "    raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
        "        schema_utils.schema_from_feature_spec(\n",
        "            {_LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=_INT_DTYPE),}\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    return train_raw_data, raw_data_metadata\n",
        "\n",
        "def _lookup_fn(y, deferred_vocab_filename_tensor):\n",
        "    with contextlib2.ExitStack() as stack:\n",
        "      if tf.executing_eagerly():\n",
        "        stack.enter_context(tf.init_scope())\n",
        "      initializer = tf.lookup.TextFileInitializer(\n",
        "          filename=deferred_vocab_filename_tensor,\n",
        "          key_dtype=tf.string,\n",
        "          key_index=1,\n",
        "          value_dtype=tf.int64,\n",
        "          value_index=0,\n",
        "          delimiter=' ')\n",
        "      table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n",
        "      size = table.size()\n",
        "    return table.lookup(y), size\n",
        "\n",
        "def example_label_preprocessing(tensor: tf.Tensor) -> tf.Tensor:\n",
        "    tensor = tf.squeeze(tensor, axis=-1)\n",
        "    tensor = tf.as_string(tensor)\n",
        "    key_vocab = tft.count_per_key(tensor, key_vocabulary_filename='abc')\n",
        "    y = tft.apply_vocabulary(tensor, key_vocab, lookup_fn=_lookup_fn)\n",
        "    return tf.strings.to_number(tensor)\n",
        "\n",
        "\n",
        "def _train_and_retrieve_trained_data(train_data, feature_name):\n",
        "    def preprocessing_fn(inputs):\n",
        "        label = inputs[_LABEL_KEY]\n",
        "        return {feature_name: example_label_preprocessing(tensor=label)}\n",
        "    \n",
        "    # apply preprocessing function to retrieve transform ops\n",
        "    train_transformed = train_data | tft_beam.AnalyzeAndTransformDataset(\n",
        "        preprocessing_fn\n",
        "    )\n",
        "    return train_transformed\n",
        "\n",
        "\n",
        "with tft_beam.Context(\n",
        "        temp_dir=_TEMP_DIR , force_tf_compat_v1=False\n",
        "):\n",
        "    _data = _generate_data_vector()\n",
        "    _FEATURE_NAME = \"feature\"\n",
        "    trained_data = _train_and_retrieve_trained_data(_data, _FEATURE_NAME)\n",
        "    print(trained_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tables initialized inside a tf.function will be re-initialized on every invocation of the function. This re-initialization can have significant impact on performance. Consider lifting them out of the graph context using `tf.init_scope`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tables initialized inside a tf.function will be re-initialized on every invocation of the function. This re-initialization can have significant impact on performance. Consider lifting them out of the graph context using `tf.init_scope`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-3c7b0d2f-50f8-44d8-9ef6-27df74cc007f.json']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpubhzvj5o/tftransform_tmp/8af014c4fca647daad7052eaa3e45c37/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpubhzvj5o/tftransform_tmp/8af014c4fca647daad7052eaa3e45c37/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpubhzvj5o/tftransform_tmp/72ea648b8696408eb8f888a801350735/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpubhzvj5o/tftransform_tmp/72ea648b8696408eb8f888a801350735/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(([{'feature': 1.0}, {'feature': 0.0}, {'feature': 0.0}, {'feature': 0.0}], BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
            "  name: \"feature\"\n",
            "  type: FLOAT\n",
            "  presence {\n",
            "    min_fraction: 1.0\n",
            "  }\n",
            "  shape {\n",
            "  }\n",
            "}\n",
            "}, deferred_metadata=[{'_schema': feature {\n",
            "  name: \"feature\"\n",
            "  type: FLOAT\n",
            "  presence {\n",
            "    min_fraction: 1.0\n",
            "  }\n",
            "  shape {\n",
            "  }\n",
            "}\n",
            "}], asset_map={})), (['/tmp/tmpubhzvj5o/tftransform_tmp/72ea648b8696408eb8f888a801350735'], BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
            "  name: \"feature\"\n",
            "  type: FLOAT\n",
            "  presence {\n",
            "    min_fraction: 1.0\n",
            "  }\n",
            "  shape {\n",
            "  }\n",
            "}\n",
            "}, deferred_metadata=[{'_schema': feature {\n",
            "  name: \"feature\"\n",
            "  type: FLOAT\n",
            "  presence {\n",
            "    min_fraction: 1.0\n",
            "  }\n",
            "  shape {\n",
            "  }\n",
            "}\n",
            "}], asset_map={})))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
